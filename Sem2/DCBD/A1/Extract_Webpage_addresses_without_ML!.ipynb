{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCx2oqdyBwDGuHMCK4iAbf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gauranga2022/Fun-with-Python/blob/main/Extract_Webpage_addresses_without_ML!.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement\n",
        "Indian addresses show up on several web pages. For example, see https://www.cmi.ac.in/merchant.php #Contact.\n",
        "\n",
        "The goal is to extract the website adresses without using ML techniques!"
      ],
      "metadata": {
        "id": "c0PPsKR2-kP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Spazer tool for processing web pages\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import pathlib\n",
        "\n",
        "#Variables to track the input, output and gained space\n",
        "space_gained = 0\n",
        "space_input = 0\n",
        "space_output = 0\n",
        "\n",
        "print(\"Welcome to Spazer\\n\")\n",
        "\n",
        "for x in range(10):\n",
        "    filename = str(x) + \".html\"\n",
        "    file = pathlib.Path('input/' + filename)\n",
        "    if (file.exists()):\n",
        "\n",
        "        #Read each file\n",
        "        print(\"Reading \" + filename)\n",
        "        f = open('input/' + filename, 'r', errors=\"ignore\")\n",
        "        contents = f.read()\n",
        "\n",
        "        #Remove html tags\n",
        "        soup = BeautifulSoup(contents, 'lxml')\n",
        "        output = soup.get_text()\n",
        "\n",
        "        #Your code begins  ###############################\n",
        "\n",
        "        import re\n",
        "        import pandas as pd\n",
        "\n",
        "\n",
        "        lines = output.split(\"\\n\")\n",
        "        for i, line in enumerate(lines):\n",
        "            if line != \"\":\n",
        "                lines[i] = line.strip()\n",
        "        output = \"\"\n",
        "        for line in lines:\n",
        "            if line != \"\":\n",
        "                output += line+\"\\n\"\n",
        "\n",
        "        buffer_l = 90\n",
        "        buffer_r = 10\n",
        "\n",
        "\n",
        "        states_and_ut_list_caps = ['Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar', 'Chhattisgarh',\n",
        "                                   'Goa', 'Gujarat', 'Haryana', 'Himachal Pradesh', 'Jharkhand',\n",
        "                                   'Karnataka', 'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur',\n",
        "                                   'Meghalaya', 'Mizoram', 'Nagaland', 'Odisha', 'Punjab', 'Rajasthan',\n",
        "                                   'Sikkim', 'Tamil Nadu', 'Telangana', 'Tripura', 'Uttar Pradesh',\n",
        "                                   'Uttarakhand', 'West Bengal', 'Andaman and Nicobar Islands',\n",
        "                                   'Chandigarh', 'Dadra and Nagar Haveli and Daman and Diu','DNHDD',\n",
        "                                   'Daman and Diu','Dadra and Nagar Haveli', 'Lakshadweep', 'Delhi',\n",
        "                                   'Puducherry', 'Ladakh', 'Jammu and Kashmir']\n",
        "\n",
        "\n",
        "\n",
        "        states_and_ut_list = []\n",
        "\n",
        "        for place in states_and_ut_list_caps:\n",
        "            states_and_ut_list.append(place.lower())\n",
        "\n",
        "        df = pd.read_csv(\"Pincode_30052019.csv\", encoding='windows-1252')\n",
        "\n",
        "        pincode_list = set()\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            pincode = row[\"Pincode\"]\n",
        "            pincode_list.add(pincode)\n",
        "        pincode_list = sorted(list(pincode_list))\n",
        "\n",
        "        district_list = set()\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            district = row[\"District\"]\n",
        "            if type(district) == str:\n",
        "                district_list.add(district.lower())\n",
        "\n",
        "        district_list = sorted(list(district_list))\n",
        "\n",
        "\n",
        "        def merge(A, B):\n",
        "            m, n = len(A), len(B)\n",
        "            i, j = 0, 0\n",
        "            answer = []\n",
        "            while i < m and j < n:\n",
        "                if A[i] <= B[j]:\n",
        "                    answer.append(A[i])\n",
        "                    i += 1\n",
        "                else:\n",
        "                    answer.append(B[j])\n",
        "                    j += 1\n",
        "            if i == m:\n",
        "                answer += B[j:]\n",
        "            if j == n:\n",
        "                answer += A[i:]\n",
        "            return answer\n",
        "\n",
        "        place_list = merge(district_list, states_and_ut_list)\n",
        "\n",
        "        intervals = []\n",
        "\n",
        "        for place in place_list:\n",
        "            i = 0\n",
        "            while i < len(output):\n",
        "                match = re.search(f\"\" + place, output[i:], re.IGNORECASE)\n",
        "                if match:\n",
        "                    a, b = match.span()\n",
        "                    a += i\n",
        "                    b += i\n",
        "                    i = b\n",
        "                    a, b = a-buffer_l, b+buffer_r\n",
        "                    if a < 0:\n",
        "                        a = 0\n",
        "                    intervals.append((a, b))\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "\n",
        "        for pincode in pincode_list:\n",
        "            i = 0\n",
        "            while i < len(output):\n",
        "                pincode = str(pincode)\n",
        "                l,r = pincode[:3], pincode[3:]\n",
        "                match = re.search(f\"\" + l + \"\\s?\" + r, output[i:])\n",
        "                if match:\n",
        "                    a, b = match.span()\n",
        "                    a += i\n",
        "                    b += i\n",
        "                    i = b\n",
        "                    a, b = a-buffer_l, b+buffer_r\n",
        "                    if a < 0:\n",
        "                        a = 0\n",
        "                    intervals.append((a, b))\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "\n",
        "        def merge_intervals(intervals):\n",
        "            if not intervals:\n",
        "                return []\n",
        "\n",
        "            sorted_intervals = sorted(intervals, key=lambda x: x[0])\n",
        "\n",
        "            merged_intervals = [sorted_intervals[0]]\n",
        "\n",
        "            for interval in sorted_intervals[1:]:\n",
        "                current_start, current_end = merged_intervals[-1]\n",
        "                interval_start, interval_end = interval\n",
        "\n",
        "                if current_end >= interval_start:\n",
        "                    merged_intervals[-1] = (current_start, max(current_end, interval_end))\n",
        "                else:\n",
        "                    merged_intervals.append(interval)\n",
        "\n",
        "            return merged_intervals\n",
        "\n",
        "        intervals = merge_intervals(intervals)\n",
        "\n",
        "        result = output\n",
        "        output = \"\"\n",
        "        for (x, y) in intervals:\n",
        "            output += result[x:y] + \"\\n\"\n",
        "\n",
        "        lines = output.split(\"\\n\")\n",
        "        for i, line in enumerate(lines):\n",
        "            if line != \"\":\n",
        "                lines[i] = line.strip()\n",
        "\n",
        "        output = \"\"\n",
        "        for line in lines:\n",
        "            if line != \"\":\n",
        "                output += line+\"\\n\"\n",
        "\n",
        "\n",
        "        #Your code ends  #################################\n",
        "\n",
        "        #Write the output variable contents to output/ folder.\n",
        "        print (\"Writing reduced \" + filename)\n",
        "        fw = open('output/' + filename, \"w\")\n",
        "        fw.write(output)\n",
        "        fw.close()\n",
        "        f.close()\n",
        "\n",
        "        #Calculate space savings\n",
        "        space_input = space_input + len(contents)\n",
        "        space_output = space_output + len(output)\n",
        "\n",
        "space_gained = round((space_input - space_output) * 100 / space_input, 2)\n",
        "\n",
        "print(\"\\nTotal Space used by input files = \" + str(space_input) + \" characters.\")\n",
        "print(\"Total Space used by output files = \" + str(space_output) + \" characters.\")\n",
        "print(\"Total Space Gained = \" + str(space_gained) + \"%\")"
      ],
      "metadata": {
        "id": "QyREwrkP_JlZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}