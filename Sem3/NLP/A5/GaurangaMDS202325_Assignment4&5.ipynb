{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25FK6cAKan75",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-24T08:15:00.231620Z",
          "iopub.status.busy": "2024-10-24T08:15:00.230741Z",
          "iopub.status.idle": "2024-10-24T08:15:06.054130Z",
          "shell.execute_reply": "2024-10-24T08:15:06.052833Z",
          "shell.execute_reply.started": "2024-10-24T08:15:00.231569Z"
        },
        "id": "25FK6cAKan75",
        "outputId": "8f7638f4-fe1c-46a4-86e1-c259d2b4b236",
        "papermill": {
          "duration": 6.745042,
          "end_time": "2024-10-23T18:05:22.772533",
          "exception": false,
          "start_time": "2024-10-23T18:05:16.027491",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /kaggle/working...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /kaggle/working...\n",
            "Archive:  /kaggle/working/corpora/wordnet.zip\n",
            "   creating: /kaggle/working/corpora/wordnet/\n",
            "  inflating: /kaggle/working/corpora/wordnet/lexnames  \n",
            "  inflating: /kaggle/working/corpora/wordnet/data.verb  \n",
            "  inflating: /kaggle/working/corpora/wordnet/index.adv  \n",
            "  inflating: /kaggle/working/corpora/wordnet/adv.exc  \n",
            "  inflating: /kaggle/working/corpora/wordnet/index.verb  \n",
            "  inflating: /kaggle/working/corpora/wordnet/cntlist.rev  \n",
            "  inflating: /kaggle/working/corpora/wordnet/data.adj  \n",
            "  inflating: /kaggle/working/corpora/wordnet/index.adj  \n",
            "  inflating: /kaggle/working/corpora/wordnet/LICENSE  \n",
            "  inflating: /kaggle/working/corpora/wordnet/citation.bib  \n",
            "  inflating: /kaggle/working/corpora/wordnet/noun.exc  \n",
            "  inflating: /kaggle/working/corpora/wordnet/verb.exc  \n",
            "  inflating: /kaggle/working/corpora/wordnet/README  \n",
            "  inflating: /kaggle/working/corpora/wordnet/index.sense  \n",
            "  inflating: /kaggle/working/corpora/wordnet/data.noun  \n",
            "  inflating: /kaggle/working/corpora/wordnet/data.adv  \n",
            "  inflating: /kaggle/working/corpora/wordnet/index.noun  \n",
            "  inflating: /kaggle/working/corpora/wordnet/adj.exc  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
        "from typing import List, Dict\n",
        "from itertools import chain\n",
        "\n",
        "data_dir = Path('/kaggle/input/')\n",
        "output_dir = Path('/kaggle/working/')\n",
        "\n",
        "nltk.download('stopwords', download_dir=output_dir)\n",
        "nltk.download('wordnet', download_dir=output_dir)\n",
        "!unzip -o /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora/\n",
        "\n",
        "nltk.data.path.append(output_dir)\n",
        "stopwords = set(stopwords.words('english'))\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j-K-nS9rqYGK",
      "metadata": {
        "id": "j-K-nS9rqYGK"
      },
      "source": [
        "## **Task-1**. Use the COVID-19 corpus\n",
        "Extract all the abstracts from the COVID-19 text files and use them as the corpus. Ensure that you create\n",
        "a vocabulary of around 10,000 words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B3yYWC4Han8C",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-24T08:15:06.057423Z",
          "iopub.status.busy": "2024-10-24T08:15:06.056721Z",
          "iopub.status.idle": "2024-10-24T08:21:58.796892Z",
          "shell.execute_reply": "2024-10-24T08:21:58.795706Z",
          "shell.execute_reply.started": "2024-10-24T08:15:06.057383Z"
        },
        "id": "B3yYWC4Han8C",
        "outputId": "5d7300ea-388e-4b55-96a1-6fb2061995cf",
        "papermill": {
          "duration": 415.528141,
          "end_time": "2024-10-23T18:12:18.308066",
          "exception": false,
          "start_time": "2024-10-23T18:05:22.779925",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of the vocabulary: 10000\n"
          ]
        }
      ],
      "source": [
        "abstracts = []\n",
        "json_files = glob.glob(f\"{data_dir}/pdf_json/pdf_json/*json\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for json_file in json_files:\n",
        "    with open(json_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    abstract_ = []\n",
        "    for abstract in data['abstract']:\n",
        "        abstract = re.sub(r'[^a-z\\s]', '', abstract['text'].strip().lower())\n",
        "        for word in abstract.split():\n",
        "            word = lemmatizer.lemmatize(word)\n",
        "            if word not in stopwords and word != '':\n",
        "                abstract_.append(word)\n",
        "        abstracts.append(abstract_)\n",
        "\n",
        "c = Counter([w for abstract in abstracts for w in abstract])\n",
        "\n",
        "# Removing any word with the length less than 2\n",
        "vocab_counter = Counter({w:v for w, v in c.items() if len(w) > 2})\n",
        "\n",
        "# Taking most common 10000 words\n",
        "vocab = set(w[0] for w in vocab_counter.most_common(10000))\n",
        "print(f\"Length of the vocabulary: {len(vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_IPktjPVan8E",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-24T08:21:58.798517Z",
          "iopub.status.busy": "2024-10-24T08:21:58.798173Z",
          "iopub.status.idle": "2024-10-24T08:22:01.982199Z",
          "shell.execute_reply": "2024-10-24T08:22:01.981082Z",
          "shell.execute_reply.started": "2024-10-24T08:21:58.798480Z"
        },
        "id": "_IPktjPVan8E",
        "papermill": {
          "duration": 2.663788,
          "end_time": "2024-10-23T18:12:20.978838",
          "exception": false,
          "start_time": "2024-10-23T18:12:18.315050",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Creating the corpus with most common 10000 words\n",
        "abstracts = [[w for w in abstract if w in vocab] for abstract in abstracts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hMA8G2H7an8G",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-24T08:22:01.984936Z",
          "iopub.status.busy": "2024-10-24T08:22:01.984577Z",
          "iopub.status.idle": "2024-10-24T08:22:02.007250Z",
          "shell.execute_reply": "2024-10-24T08:22:02.006030Z",
          "shell.execute_reply.started": "2024-10-24T08:22:01.984901Z"
        },
        "id": "hMA8G2H7an8G",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class SkipGramDataset(IterableDataset):\n",
        "    def __init__(self,\n",
        "                 documents: List[List[str]],\n",
        "                 window_size: int = 2,\n",
        "                 num_negative: int = 5,\n",
        "                 min_count: int = 5,\n",
        "                 sampling_table_size: int = 1e8):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            documents: List of documents, where each document is a list of words\n",
        "            window_size: Maximum distance between target and context words\n",
        "            num_negative: Number of negative samples per positive pair\n",
        "            min_count: Minimum frequency of words to include in vocab\n",
        "            sampling_table_size: Size of the negative sampling table\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.documents = documents\n",
        "        self.window_size = window_size\n",
        "        self.num_negative = num_negative\n",
        "\n",
        "        # Build vocabulary and frequency table\n",
        "        print(\"Building vocabulary...\")\n",
        "        self.vocab, self.word_freqs = self._build_vocab(min_count)\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "        # Create negative sampling table\n",
        "        print(\"Creating negative sampling table...\")\n",
        "        self.negative_table = self._create_negative_table(int(sampling_table_size))\n",
        "\n",
        "        # Pre-calculate document lengths and cumulative lengths for efficient indexing\n",
        "        self.doc_lengths = [len(doc) for doc in documents]\n",
        "        self.cumsum_lengths = np.cumsum(self.doc_lengths)\n",
        "        self.total_words = self.cumsum_lengths[-1]\n",
        "\n",
        "        # Calculate approximate number of pairs for length estimation\n",
        "        words_per_window = window_size * 2\n",
        "        self.approx_pairs = self.total_words * words_per_window\n",
        "\n",
        "    def _build_vocab(self, min_count):\n",
        "        \"\"\"Build vocabulary and compute normalized word frequencies\"\"\"\n",
        "        # Count words\n",
        "        word_counts = Counter(chain.from_iterable(self.documents))\n",
        "\n",
        "        # Filter by minimum count and create vocabulary\n",
        "        filtered_words = [(word, count) for word, count in word_counts.items()\n",
        "                         if count >= min_count]\n",
        "        vocab = {word: idx for idx, (word, _) in enumerate(filtered_words)}\n",
        "\n",
        "        # Compute normalized frequencies for negative sampling\n",
        "        freqs = np.array([count for _, count in filtered_words], dtype=np.float32)\n",
        "        freqs = np.power(freqs, 0.75)\n",
        "        freqs = freqs / freqs.sum()\n",
        "\n",
        "        return vocab, freqs\n",
        "\n",
        "    def _create_negative_table(self, size):\n",
        "        \"\"\"Create table for efficient negative sampling\"\"\"\n",
        "        table = np.zeros(size, dtype=np.int32)\n",
        "        p = 0\n",
        "        i = 0\n",
        "\n",
        "        # Fill table according to word frequencies\n",
        "        for word_idx, freq in enumerate(self.word_freqs):\n",
        "            p += freq\n",
        "            while i < size and i / size < p:\n",
        "                table[i] = word_idx\n",
        "                i += 1\n",
        "\n",
        "        return table\n",
        "\n",
        "    def _get_negative_samples(self, pos_id, context_id):\n",
        "        \"\"\"Get negative samples, excluding positive examples\"\"\"\n",
        "        samples = []\n",
        "        while len(samples) < self.num_negative:\n",
        "            neg_id = self.negative_table[random.randint(0, len(self.negative_table) - 1)]\n",
        "            if neg_id != pos_id and neg_id != context_id:\n",
        "                samples.append(neg_id)\n",
        "        return samples\n",
        "\n",
        "    def _get_doc_and_pos(self, index):\n",
        "        \"\"\"Get document and word position from global index\"\"\"\n",
        "        doc_idx = np.searchsorted(self.cumsum_lengths, index, side='right')\n",
        "        if doc_idx == 0:\n",
        "            pos = index\n",
        "        else:\n",
        "            pos = index - self.cumsum_lengths[doc_idx - 1]\n",
        "        return self.documents[doc_idx], pos\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Generate pairs on-the-fly\"\"\"\n",
        "        worker_info = torch.utils.data.get_worker_info()\n",
        "        if worker_info is None:\n",
        "            # Single-process data loading\n",
        "            start_idx = 0\n",
        "            end_idx = self.total_words\n",
        "        else:\n",
        "            # Multi-process data loading\n",
        "            per_worker = int(np.ceil(self.total_words / worker_info.num_workers))\n",
        "            worker_id = worker_info.id\n",
        "            start_idx = worker_id * per_worker\n",
        "            end_idx = min(start_idx + per_worker, self.total_words)\n",
        "\n",
        "        # Generate pairs for this worker's range\n",
        "        for idx in range(start_idx, end_idx):\n",
        "            document, pos = self._get_doc_and_pos(idx)\n",
        "\n",
        "            # Skip if word not in vocabulary\n",
        "            if document[pos] not in self.vocab:\n",
        "                continue\n",
        "\n",
        "            target_id = self.vocab[document[pos]]\n",
        "\n",
        "            # Generate context words within window\n",
        "            window_start = max(0, pos - self.window_size)\n",
        "            window_end = min(len(document), pos + self.window_size + 1)\n",
        "\n",
        "            for context_pos in range(window_start, window_end):\n",
        "                if context_pos != pos and document[context_pos] in self.vocab:\n",
        "                    context_id = self.vocab[document[context_pos]]\n",
        "                    neg_samples = self._get_negative_samples(target_id, context_id)\n",
        "\n",
        "                    yield (\n",
        "                        torch.tensor(target_id, dtype=torch.long),\n",
        "                        torch.tensor(context_id, dtype=torch.long),\n",
        "                        torch.tensor(neg_samples, dtype=torch.long)\n",
        "                    )\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Approximate length for progress bars\"\"\"\n",
        "        return self.approx_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FCpSzeo8an8I",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-24T06:22:24.375612Z",
          "iopub.status.busy": "2024-10-24T06:22:24.375158Z",
          "iopub.status.idle": "2024-10-24T06:23:12.668459Z",
          "shell.execute_reply": "2024-10-24T06:23:12.667081Z",
          "shell.execute_reply.started": "2024-10-24T06:22:24.375570Z"
        },
        "id": "FCpSzeo8an8I",
        "outputId": "1ec0e4e6-5f56-4f90-d2f2-8e772d9408fd",
        "papermill": {
          "duration": 40.7564,
          "end_time": "2024-10-23T18:13:02.038752",
          "exception": false,
          "start_time": "2024-10-23T18:12:21.282352",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building vocabulary...\n",
            "Creating negative sampling table...\n"
          ]
        }
      ],
      "source": [
        "# Creating dataloader\n",
        "batch_size = 1024\n",
        "window_size = 2\n",
        "num_negative = 5\n",
        "min_count = 5\n",
        "num_workers = 4\n",
        "\n",
        "dataset = SkipGramDataset(\n",
        "    documents=abstracts,\n",
        "    window_size=window_size,\n",
        "    num_negative=num_negative,\n",
        "    min_count=min_count\n",
        ")\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    shuffle=False,\n",
        "    collate_fn=lambda batch: (\n",
        "        torch.stack([item[0] for item in batch]),\n",
        "        torch.stack([item[1] for item in batch]),\n",
        "        torch.stack([item[2] for item in batch])\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mjOtgl99q_76",
      "metadata": {
        "id": "mjOtgl99q_76"
      },
      "source": [
        "## **Task-3** Description of the model\n",
        "\n",
        "Skip-gram model with negative sampling, used for word embedding learning.\n",
        "\n",
        "**1. Architecture:**\n",
        "- Uses one embedding matrice for target words and one linear layer for context predictions\n",
        "- Implements negative sampling to improve training efficiency.\n",
        "\n",
        "**2. Main Components:**\n",
        "- `target_embeddings`: Embedding layer for target words\n",
        "- `context_linear`: Linear layer for predicting context words\n",
        "- Both layers are initialized with uniform random weights in [-0.1, 0.1]\n",
        "\n",
        "**3. Forward Pass:**\n",
        "- Takes target words, context words, and negative samples as input\n",
        "- Calculates positive scores for true context words\n",
        "- Calculates negative scores for randomly sampled negative words\n",
        "- Combines both into a negative sampling loss function\n",
        "\n",
        "The model is designed for efficient training on large text corpora to learn word representations that capture semantic relationships between words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GB1O3AuFan8J",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-24T08:22:02.009670Z",
          "iopub.status.busy": "2024-10-24T08:22:02.009242Z",
          "iopub.status.idle": "2024-10-24T08:22:02.029298Z",
          "shell.execute_reply": "2024-10-24T08:22:02.028073Z",
          "shell.execute_reply.started": "2024-10-24T08:22:02.009603Z"
        },
        "id": "GB1O3AuFan8J",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class SkipGramHybrid(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding layer for target words\n",
        "        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Linear layer for context predictions\n",
        "        self.context_linear = nn.Linear(embedding_dim, vocab_size, bias=False)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.target_embeddings.weight.data.uniform_(-0.1, 0.1)\n",
        "        self.context_linear.weight.data.uniform_(-0.1, 0.1)\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "    def forward(self, target_words, context_words, negative_words):\n",
        "        num_negative = negative_words.size(1)\n",
        "\n",
        "        # Get target embeddings [batch_size, embedding_dim]\n",
        "        target_embeds = self.target_embeddings(target_words)\n",
        "\n",
        "        # Compute scores for positive context words\n",
        "        pos_scores = self.context_linear(target_embeds)\n",
        "        pos_scores = torch.gather(pos_scores, 1, context_words.unsqueeze(1))\n",
        "        pos_loss = -torch.log(torch.sigmoid(pos_scores)).squeeze()\n",
        "\n",
        "        # Compute scores for negative samples\n",
        "        neg_scores = self.context_linear(target_embeds).unsqueeze(1)\n",
        "        neg_scores = torch.gather(neg_scores.expand(-1, num_negative, -1), 2,\n",
        "                                negative_words.unsqueeze(2)).squeeze(2)\n",
        "        neg_loss = -torch.sum(torch.log(torch.sigmoid(-neg_scores)), dim=1)\n",
        "\n",
        "        return torch.mean(pos_loss + neg_loss)\n",
        "\n",
        "\n",
        "def train_skipgram(dataloader, embedding_dim=100, batch_size=1024, num_epochs=20, lr=0.001):\n",
        "    # Initialize model and optimizer\n",
        "    model = SkipGramHybrid(len(dataset.vocab), embedding_dim).to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    training_loss = []\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for target, context, negative in tqdm(dataloader, desc=f'Training: Epoch {epoch+1}/{num_epochs}'):\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(target.to(device), context.to(device), negative.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        training_loss.append(avg_loss)\n",
        "        print(f\"Epoch {epoch}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return model, dataset.vocab, training_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2R_haZXRan8L",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-23T18:13:02.057553Z",
          "iopub.status.busy": "2024-10-23T18:13:02.056674Z",
          "iopub.status.idle": "2024-10-23T19:42:16.228534Z",
          "shell.execute_reply": "2024-10-23T19:42:16.227374Z"
        },
        "id": "2R_haZXRan8L",
        "outputId": "8c63bf41-f425-4261-ee7e-af9c9aeb9bfc",
        "papermill": {
          "duration": 5354.183211,
          "end_time": "2024-10-23T19:42:16.230625",
          "exception": false,
          "start_time": "2024-10-23T18:13:02.047414",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 1/20:  99%|█████████▉| 7525/7589 [04:24<00:02, 28.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Average Loss: 2.4730\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 2/20:  99%|█████████▉| 7525/7589 [04:25<00:02, 28.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 2.0011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 3/20:  99%|█████████▉| 7525/7589 [04:24<00:02, 28.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Loss: 1.8402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 4/20:  99%|█████████▉| 7525/7589 [04:23<00:02, 28.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Loss: 1.7626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 5/20:  99%|█████████▉| 7525/7589 [04:24<00:02, 28.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Loss: 1.7173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 6/20:  99%|█████████▉| 7525/7589 [04:22<00:02, 28.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Average Loss: 1.6883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 7/20:  99%|█████████▉| 7525/7589 [04:26<00:02, 28.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Average Loss: 1.6679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 8/20:  99%|█████████▉| 7525/7589 [04:26<00:02, 28.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Average Loss: 1.6522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 9/20:  99%|█████████▉| 7525/7589 [04:27<00:02, 28.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Average Loss: 1.6413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 10/20:  99%|█████████▉| 7525/7589 [04:27<00:02, 28.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Average Loss: 1.6317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 11/20:  99%|█████████▉| 7525/7589 [04:27<00:02, 28.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Average Loss: 1.6240\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 12/20:  99%|█████████▉| 7525/7589 [04:26<00:02, 28.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Average Loss: 1.6185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 13/20:  99%|█████████▉| 7525/7589 [04:31<00:02, 27.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Average Loss: 1.6131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 14/20:  99%|█████████▉| 7525/7589 [04:29<00:02, 27.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Average Loss: 1.6085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 15/20:  99%|█████████▉| 7525/7589 [04:32<00:02, 27.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Average Loss: 1.6049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 16/20:  99%|█████████▉| 7525/7589 [04:27<00:02, 28.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Average Loss: 1.6016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 17/20:  99%|█████████▉| 7525/7589 [04:30<00:02, 27.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Average Loss: 1.5990\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 18/20:  99%|█████████▉| 7525/7589 [04:30<00:02, 27.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Average Loss: 1.5960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 19/20:  99%|█████████▉| 7525/7589 [04:32<00:02, 27.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Average Loss: 1.5938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: Epoch 20/20:  99%|█████████▉| 7525/7589 [04:32<00:02, 27.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Average Loss: 1.5918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model, vocab, training_loss = train_skipgram(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eg6IN35QuFLM",
      "metadata": {
        "id": "eg6IN35QuFLM"
      },
      "source": [
        "## **Task-5.** Plot Epochs vs. Training Error\n",
        "Plot the relationship between the number of epochs and the training error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cmtVN7MtVu_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "9cmtVN7MtVu_",
        "outputId": "f77bd8b0-6016-4b33-dbf4-8ee7b0ef2bd1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(training_loss, marker='o', linestyle='-', color='b', markersize=5)\n",
        "plt.title('Training Loss per Epoch', fontsize=16)\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.ylabel('Training Loss', fontsize=14)\n",
        "plt.xticks(range(len(training_loss)))\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2SAkRi4lan8Q",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-23T19:42:27.878227Z",
          "iopub.status.busy": "2024-10-23T19:42:27.877848Z",
          "iopub.status.idle": "2024-10-23T19:42:27.897887Z",
          "shell.execute_reply": "2024-10-23T19:42:27.897172Z"
        },
        "id": "2SAkRi4lan8Q",
        "papermill": {
          "duration": 2.922969,
          "end_time": "2024-10-23T19:42:27.899682",
          "exception": false,
          "start_time": "2024-10-23T19:42:24.976713",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "torch.save(model.state_dict(), '/kaggle/working/model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PCG7GtqWan8S",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-24T08:22:02.031132Z",
          "iopub.status.busy": "2024-10-24T08:22:02.030684Z",
          "iopub.status.idle": "2024-10-24T08:22:25.009088Z",
          "shell.execute_reply": "2024-10-24T08:22:25.007896Z",
          "shell.execute_reply.started": "2024-10-24T08:22:02.031083Z"
        },
        "id": "PCG7GtqWan8S",
        "outputId": "53347704-6f0b-425f-8782-96d5fff07f8f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building vocabulary...\n",
            "Creating negative sampling table...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36/394975449.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/kaggle/input/skipgram_model.pth', map_location=device))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = dataset.vocab\n",
        "word_to_idx = {w:i for w,i in vocab.items()}\n",
        "idx_to_word = {i:w for w,i in vocab.items()}\n",
        "embedding_dim = 100\n",
        "\n",
        "# Loading the model\n",
        "model = SkipGramHybrid(len(vocab), embedding_dim).to(device)\n",
        "model.load_state_dict(torch.load('/kaggle/input/skipgram_model.pth', map_location=device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Fzb-WnbxuMuI",
      "metadata": {
        "id": "Fzb-WnbxuMuI"
      },
      "source": [
        "## **Task-7.** Test Analogies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FNM01Rojan8U",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-24T08:22:25.011109Z",
          "iopub.status.busy": "2024-10-24T08:22:25.010541Z",
          "iopub.status.idle": "2024-10-24T08:22:25.137601Z",
          "shell.execute_reply": "2024-10-24T08:22:25.136218Z",
          "shell.execute_reply.started": "2024-10-24T08:22:25.011056Z"
        },
        "id": "FNM01Rojan8U",
        "outputId": "1873d483-7fd9-450f-e4c8-8efa90fb624b",
        "papermill": {
          "duration": 2.843358,
          "end_time": "2024-10-23T19:42:45.003104",
          "exception": false,
          "start_time": "2024-10-23T19:42:42.159746",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing COVID-19 Related Analogies:\n",
            "\n",
            "antigen : negative :: infection : ?\n",
            "Predicted: vaccine\n",
            "Confidence (cosine similarity): 0.2898\n",
            "\n",
            "antibody : immunity :: vaccination : ?\n",
            "Predicted: proteolysis\n",
            "Confidence (cosine similarity): 0.3224\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_word_vector(word, word_to_idx, embeddings):\n",
        "    \"\"\"Get the embedding vector for a word\"\"\"\n",
        "    if word in word_to_idx:\n",
        "        idx = word_to_idx[word]\n",
        "        # Convert to tensor and get embedding\n",
        "        idx_tensor = torch.tensor([idx])\n",
        "        return embeddings(idx_tensor).detach()\n",
        "    return None\n",
        "\n",
        "def cosine_similarity_torch(v1, v2):\n",
        "    \"\"\"Calculate cosine similarity between two vectors using PyTorch\"\"\"\n",
        "    return F.cosine_similarity(v1.unsqueeze(0), v2.unsqueeze(0))\n",
        "\n",
        "def find_closest_word(vector, word_to_idx, idx_to_word, embeddings, exclude_words=None):\n",
        "    \"\"\"Find the word with the closest embedding to the given vector\"\"\"\n",
        "    if exclude_words is None:\n",
        "        exclude_words = set()\n",
        "\n",
        "    # Create tensor of all word indices\n",
        "    all_indices = torch.tensor(list(word_to_idx.values()))\n",
        "\n",
        "    # Get embeddings for all words\n",
        "    all_embeddings = embeddings(all_indices)\n",
        "\n",
        "    # Calculate cosine similarities using PyTorch operations\n",
        "    similarities = F.cosine_similarity(vector.unsqueeze(0), all_embeddings)\n",
        "\n",
        "    # Convert to numpy for easier processing\n",
        "    similarities = similarities.detach().squeeze()\n",
        "\n",
        "    # Sort indices by similarity\n",
        "    sorted_indices = torch.argsort(similarities, descending=True).numpy()\n",
        "\n",
        "    # Find the closest word that's not in exclude_words\n",
        "    for idx in sorted_indices:\n",
        "        word = idx_to_word[idx]\n",
        "        if word not in exclude_words:\n",
        "            return word, similarities[idx]\n",
        "\n",
        "    return None, None\n",
        "\n",
        "def test_covid_analogy(word1, word2, word3, word_to_idx, idx_to_word, embeddings):\n",
        "    \"\"\"\n",
        "    Test analogy of the form: word1 : word2 :: word3 : ?\n",
        "    Returns the word that best completes the analogy\n",
        "    \"\"\"\n",
        "    # Get word vectors\n",
        "    v1 = get_word_vector(word1, word_to_idx, embeddings)\n",
        "    v2 = get_word_vector(word2, word_to_idx, embeddings)\n",
        "    v3 = get_word_vector(word3, word_to_idx, embeddings)\n",
        "\n",
        "    if v1 is None or v2 is None or v3 is None:\n",
        "        return None, None\n",
        "\n",
        "    # Calculate the expected vector for word4\n",
        "    # Using the formula: v4 ≈ v2 - v1 + v3\n",
        "    target_vector = v2 - v1 + v3\n",
        "\n",
        "    # Find the closest word to the target vector\n",
        "    exclude_words = {word1, word2, word3}\n",
        "    return find_closest_word(target_vector, word_to_idx, idx_to_word, embeddings, exclude_words)\n",
        "\n",
        "def evaluate_covid_analogies(model, word_to_idx, idx_to_word):\n",
        "    \"\"\"\n",
        "    Test a set of COVID-19 related analogies\n",
        "    \"\"\"\n",
        "    print(\"Testing COVID-19 Related Analogies:\\n\")\n",
        "\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Use the target embeddings for word vectors\n",
        "    embeddings = model.target_embeddings\n",
        "\n",
        "    # Example analogies using COVID-19 terms\n",
        "    analogies = [\n",
        "        (\"antigen\", \"negative\", \"infection\"),\n",
        "        (\"antibody\", \"immunity\", \"vaccination\")\n",
        "    ]\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for inference\n",
        "        for a1, a2, a3 in analogies:\n",
        "            predicted_word, similarity = test_covid_analogy(\n",
        "                a1, a2, a3, word_to_idx, idx_to_word, embeddings\n",
        "            )\n",
        "\n",
        "            print(f\"{a1} : {a2} :: {a3} : ?\")\n",
        "            print(f\"Predicted: {predicted_word}\")\n",
        "            if similarity is not None:\n",
        "                print(f\"Confidence (cosine similarity): {similarity:.4f}\")\n",
        "            print()\n",
        "\n",
        "evaluate_covid_analogies(model, word_to_idx, idx_to_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FA7kgE9suoA8",
      "metadata": {
        "id": "FA7kgE9suoA8"
      },
      "source": [
        "## Assigment-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TLzQ9_2ban8W",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-24T08:22:25.166272Z",
          "iopub.status.busy": "2024-10-24T08:22:25.165902Z",
          "iopub.status.idle": "2024-10-24T08:22:25.224504Z",
          "shell.execute_reply": "2024-10-24T08:22:25.223393Z",
          "shell.execute_reply.started": "2024-10-24T08:22:25.166234Z"
        },
        "id": "TLzQ9_2ban8W",
        "outputId": "21f42594-bc40-4fb9-dd51-b449ee6339cd",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyzing similar words for: 'covid'\n",
            "\n",
            "Using Input Matrix (Win):\n",
            "pandemic: 0.5595\n",
            "espaa: 0.4838\n",
            "cuidados: 0.4712\n",
            "diagnstico: 0.4687\n",
            "aspectos: 0.4503\n",
            "\n",
            "Using Output Matrix (Wout):\n",
            "pandemic: 0.8617\n",
            "distancing: 0.8241\n",
            "combating: 0.8233\n",
            "resumen: 0.8226\n",
            "sgrna: 0.8203\n",
            "\n",
            "Using Averaged Matrices:\n",
            "pandemic: 0.6705\n",
            "moderatetosevere: 0.5911\n",
            "resumen: 0.5892\n",
            "espaa: 0.5829\n",
            "amid: 0.5776\n",
            "\n",
            "Using Concatenated Matrices:\n",
            "pandemic: 0.7288\n",
            "diagnstico: 0.6683\n",
            "espaa: 0.6668\n",
            "resumen: 0.6602\n",
            "cuidados: 0.6563\n",
            "\n",
            "Overlap Analysis:\n",
            "Win-Wout: 1 words in common\n",
            "Average-Win: 2 words in common\n",
            "Average-Wout: 2 words in common\n",
            "Average-Concatenate: 3 words in common\n",
            "Concatenate-Win: 4 words in common\n",
            "Concatenate-Wout: 2 words in common\n"
          ]
        }
      ],
      "source": [
        "def get_similar_words_win(word, word_to_idx, idx_to_word, model, top_k=5):\n",
        "    \"\"\"Find similar words using input embeddings (Win)\"\"\"\n",
        "    if word not in word_to_idx:\n",
        "        return []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get the word embedding from Win (target_embeddings)\n",
        "        word_idx = torch.tensor([word_to_idx[word]])\n",
        "        word_vec = model.target_embeddings(word_idx)\n",
        "\n",
        "        # Get all word embeddings\n",
        "        all_indices = torch.arange(len(word_to_idx))\n",
        "        all_embeddings = model.target_embeddings(all_indices)\n",
        "\n",
        "        # Calculate cosine similarities\n",
        "        similarities = F.cosine_similarity(word_vec, all_embeddings)\n",
        "\n",
        "        # Get top-k similar words\n",
        "        top_indices = torch.argsort(similarities, descending=True)[1:top_k+1]  # Skip the word itself\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            similar_word = idx_to_word[idx.item()]\n",
        "            similarity = similarities[idx].item()\n",
        "            results.append((similar_word, similarity))\n",
        "\n",
        "        return results\n",
        "\n",
        "def get_similar_words_wout(word, word_to_idx, idx_to_word, model, top_k=5):\n",
        "    \"\"\"Find similar words using output embeddings (Wout)\"\"\"\n",
        "    if word not in word_to_idx:\n",
        "        return []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get the word vector from Wout (context_linear weights)\n",
        "        word_idx = word_to_idx[word]\n",
        "        word_vec = model.context_linear.weight[word_idx]\n",
        "\n",
        "        # Get all word vectors from Wout\n",
        "        all_embeddings = model.context_linear.weight\n",
        "\n",
        "        # Calculate cosine similarities\n",
        "        similarities = F.cosine_similarity(word_vec.unsqueeze(0), all_embeddings)\n",
        "\n",
        "        # Get top-k similar words\n",
        "        top_indices = torch.argsort(similarities, descending=True)[1:top_k+1]  # Skip the word itself\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            similar_word = idx_to_word[idx.item()]\n",
        "            similarity = similarities[idx].item()\n",
        "            results.append((similar_word, similarity))\n",
        "\n",
        "        return results\n",
        "\n",
        "def get_similar_words_combined(word, word_to_idx, idx_to_word, model, method='average', top_k=5):\n",
        "    \"\"\"Find similar words using combined embeddings (Win and Wout)\"\"\"\n",
        "    if word not in word_to_idx:\n",
        "        return []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        word_idx = word_to_idx[word]\n",
        "\n",
        "        # Get word vectors from both matrices\n",
        "        win_vec = model.target_embeddings(torch.tensor([word_idx]))\n",
        "        wout_vec = model.context_linear.weight[word_idx]\n",
        "\n",
        "        # Combine vectors based on method\n",
        "        if method == 'concatenate':\n",
        "            word_vec = torch.cat([win_vec.squeeze(0), wout_vec])\n",
        "        else:  # average\n",
        "            word_vec = (win_vec.squeeze(0) + wout_vec) / 2\n",
        "\n",
        "        # Get combined vectors for all words\n",
        "        all_win = model.target_embeddings(torch.arange(len(word_to_idx)))\n",
        "        all_wout = model.context_linear.weight\n",
        "\n",
        "        if method == 'concatenate':\n",
        "            all_embeddings = torch.cat([all_win, all_wout], dim=1)\n",
        "        else:  # average\n",
        "            all_embeddings = (all_win + all_wout) / 2\n",
        "\n",
        "        # Calculate cosine similarities\n",
        "        similarities = F.cosine_similarity(word_vec.unsqueeze(0), all_embeddings)\n",
        "\n",
        "        # Get top-k similar words\n",
        "        top_indices = torch.argsort(similarities, descending=True)[1:top_k+1]  # Skip the word itself\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            similar_word = idx_to_word[idx.item()]\n",
        "            similarity = similarities[idx].item()\n",
        "            results.append((similar_word, similarity))\n",
        "\n",
        "        return results\n",
        "\n",
        "def compare_embeddings(word, word_to_idx, idx_to_word, model, top_k=5):\n",
        "    \"\"\"Compare similar words using different embedding approaches\"\"\"\n",
        "    print(f\"\\nAnalyzing similar words for: '{word}'\\n\")\n",
        "\n",
        "    # Get similar words using different methods\n",
        "    win_similar = get_similar_words_win(word, word_to_idx, idx_to_word, model, top_k)\n",
        "    wout_similar = get_similar_words_wout(word, word_to_idx, idx_to_word, model, top_k)\n",
        "    avg_similar = get_similar_words_combined(word, word_to_idx, idx_to_word, model, 'average', top_k)\n",
        "    concat_similar = get_similar_words_combined(word, word_to_idx, idx_to_word, model, 'concatenate', top_k)\n",
        "\n",
        "    # Print results\n",
        "    print(\"Using Input Matrix (Win):\")\n",
        "    for word, sim in win_similar:\n",
        "        print(f\"{word}: {sim:.4f}\")\n",
        "\n",
        "    print(\"\\nUsing Output Matrix (Wout):\")\n",
        "    for word, sim in wout_similar:\n",
        "        print(f\"{word}: {sim:.4f}\")\n",
        "\n",
        "    print(\"\\nUsing Averaged Matrices:\")\n",
        "    for word, sim in avg_similar:\n",
        "        print(f\"{word}: {sim:.4f}\")\n",
        "\n",
        "    print(\"\\nUsing Concatenated Matrices:\")\n",
        "    for word, sim in concat_similar:\n",
        "        print(f\"{word}: {sim:.4f}\")\n",
        "\n",
        "    # Analyze overlap between methods\n",
        "    all_methods = {\n",
        "        'Win': set(word for word, _ in win_similar),\n",
        "        'Wout': set(word for word, _ in wout_similar),\n",
        "        'Average': set(word for word, _ in avg_similar),\n",
        "        'Concatenate': set(word for word, _ in concat_similar)\n",
        "    }\n",
        "\n",
        "    # Calculate overlap statistics\n",
        "    overlap_stats = defaultdict(int)\n",
        "    for method1, words1 in all_methods.items():\n",
        "        for method2, words2 in all_methods.items():\n",
        "            if method1 < method2:  # Avoid counting pairs twice\n",
        "                overlap = len(words1.intersection(words2))\n",
        "                overlap_stats[f\"{method1}-{method2}\"] = overlap\n",
        "\n",
        "    print(\"\\nOverlap Analysis:\")\n",
        "    for pair, count in overlap_stats.items():\n",
        "        print(f\"{pair}: {count} words in common\")\n",
        "\n",
        "\n",
        "compare_embeddings(\"covid\", word_to_idx, idx_to_word, model, top_k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D64-A9f_uvRB",
      "metadata": {
        "id": "D64-A9f_uvRB"
      },
      "source": [
        "**Description of the outcome**\n",
        "\n",
        "This output compares different word embedding methods by looking at their top-5 similar word predictions, measuring how many words they share in common:\n",
        "\n",
        "1. `Win-Wout`: Only 1/5 words overlap (20%) - these methods produce quite different results\n",
        "2. `Average-Win` and `Average-Wout`: Both share 2/5 words (40%) - suggesting the Average method has moderate alignment with both approaches\n",
        "3. `Average-Concatenate`: 3/5 words in common (60%) - shows strong agreement between these methods\n",
        "4. `Concatenate-Win`: Highest overlap with 4/5 words (80%) - indicates these two methods are finding almost the same set of similar words\n",
        "5. `Concatenate-Wout`: 2/5 words in common (40%) - moderate overlap\n",
        "\n",
        "Looking at the percentages makes the relationships clearer:\n",
        "- Concatenate and Win methods are most similar (80% overlap)\n",
        "- Average and Concatenate show strong agreement (60% overlap)\n",
        "- Win and Wout are most different (20% overlap)\n",
        "- Other combinations show moderate agreement (40% overlap)\n",
        "\n",
        "This suggests that the Concatenate method might be capturing the best of both Win and Wout approaches, as it shows strong alignment with Win while maintaining some similarity with Wout."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BsNoWSrOgIDS",
      "metadata": {
        "id": "BsNoWSrOgIDS"
      },
      "source": [
        "**Task-5.** A slide related to the complexities of skipgram and CBOW model was shown in the class. Check if they\n",
        "are correct. If not, what are the correct entries?\n",
        "\n",
        "I can confirm that the complexities shown in the slide are correct:\n",
        "\n",
        "1. Skip-gram with Hierarchical Softmax: O(T·N·C·log V)\n",
        "- This is correct as the hierarchical softmax reduces the complexity from O(V) to O(log V)\n",
        "\n",
        "2. Skip-gram with Negative Sampling: O(T·N·C·k)\n",
        "- This is correct as negative sampling reduces complexity to depend on k samples instead of V\n",
        "\n",
        "3. CBOW (Continuous Bag of Words) with Hierarchical Softmax: O(T·N·C·log V)\n",
        "- This matches the expected complexity, similar to Skip-gram with hierarchical softmax\n",
        "\n",
        "4. CBOW with Negative Sampling: O(T·N·C·k)\n",
        "- This is accurate, following the same pattern as Skip-gram with negative sampling\n",
        "\n",
        "5. Cosine Similarity: O(N)\n",
        "- This is correct as it involves vector operations proportional to embedding dimension\n",
        "\n",
        "6. Analogy Task: O(V·N)\n",
        "- This is accurate as it typically involves scanning through the vocabulary while doing vector operations\n",
        "\n",
        "The definitions of variables are also correctly stated:\n",
        "- T: total number of words in corpus\n",
        "- V: vocabulary size\n",
        "- N: embedding size\n",
        "- C: context window size\n",
        "- k: number of negative samples"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 9941651,
          "datasetId": 5608831,
          "sourceId": 9707844,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30761,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 5856.484277,
      "end_time": "2024-10-23T19:42:49.643305",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-10-23T18:05:13.159028",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}